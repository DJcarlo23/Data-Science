{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from PIL import Image as im\n",
    "\n",
    "# Machine Learning\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/digit-recognizer/train.csv')\n",
    "data_test = pd.read_csv('data/digit-recognizer/test.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to see if dataset is balanced. It's easy to see from below plot that our dataset is indeed balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=data.label)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w, img_h = 28, 28\n",
    "image_array = data.iloc[3,1:].to_numpy(dtype=np.uint8)\n",
    "image_array = np.reshape(image_array, (img_w, img_h))\n",
    "image = im.fromarray(image_array)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be very helpfull to see how those numbers looks like. We can display couple of them easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "columns, rows = 5, 6\n",
    "img_w, img_h = 28, 28\n",
    "\n",
    "for i in range(1, columns*rows + 1):\n",
    "    image_array = image_array = data.iloc[i-1,1:].to_numpy(dtype=np.uint8)\n",
    "    image_array = np.reshape(image_array, (img_w, img_h))\n",
    "    image = im.fromarray(image_array)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is any missing value\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset into train and test sets\n",
    "X, y = data.iloc[:,1:], data.label\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "start = time.time()\n",
    "classificator_RF = RandomForestClassifier()\n",
    "classificator_RF.fit(X_train, y_train)\n",
    "y_pred_RF = classificator_RF.predict(X_test)\n",
    "end = time.time()\n",
    "accuracy_RF = accuracy_score(y_test, y_pred_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light Gradient Boost Classifier\n",
    "start = time.time()\n",
    "classificator_LGBMC = LGBMClassifier()\n",
    "classificator_LGBMC.fit(X_train, y_train)\n",
    "y_pred_LGBMC = classificator_LGBMC.predict(X_test)\n",
    "end = time.time()\n",
    "accuracy_LGBMC = accuracy_score(y_test, y_pred_LGBMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_LGBMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After couple of tests we can see, random forest and light gradient boost perform best of all models. Our models have nice accuracy and speed even if this is just classical algorithms. From now we will evaluate only them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest score: {}\".format(accuracy_RF))\n",
    "print(\"Light Gradient Boost Classifier score: {}\".format(accuracy_LGBMC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to compute cross-validation score for our two raw models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_RF = cross_val_score(classificator_RF, X, y, cv=5)\n",
    "# scores_LGBMC = cross_val_score(classificator_LGBMC, X, y, cv=5)\n",
    "# print(\"Random Forest CV score: {}\".format(scores_RF.mean()))\n",
    "# print(\"Light Gradient Boost Classifier CV score: {}\".format(scores_LGBMC.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Light boost still perform better than random forest. Let's make last test and visualize confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for random forest\n",
    "matrix_RF = confusion_matrix(y_test, y_pred_RF, normalize='true')\n",
    "plt.figure(figsize = (10, 7))\n",
    "sns.heatmap(matrix_RF, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for light gradient boost\n",
    "matrix_LGBMC = confusion_matrix(y_test, y_pred_LGBMC, normalize='true')\n",
    "plt.figure(figsize = (10, 7))\n",
    "sns.heatmap(matrix_LGBMC, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Light gradient boost wins in every test. That's why we will use this algorithm to recognize our digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find best hiperparameters we will use GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator_LGBMC_new = LGBMClassifier(max_bin=235)\n",
    "\n",
    "param_grid = {\n",
    "    'num_iterations': [200, 250, 350, 400],  \n",
    "}\n",
    "n_iter_search = 54\n",
    "random_search = RandomizedSearchCV(classificator_LGBMC_new, param_distributions=param_grid, n_iter=n_iter_search, cv=2, verbose=2)\n",
    "start = time.time()\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start), n_iter_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best {'num_iterations': 200, 'max_bin': 255, 'learning_rate': 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'num_iterations': 300, 'max_bin': 235, 'learning_rate': 0.1} 0.9736666666666667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will train algorithm with parameters we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(num_iterations=300, max_bin=235, learning_rate=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'ImageId': data_test.index+1, 'Label': y_pred})\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
