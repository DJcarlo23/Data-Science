{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0efa54f7f23af1d5798b652f3dd1f0fb573148954cb9e66026e20a8379bf29199",
   "display_name": "Python 3.7.10 64-bit ('Kaggle': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data/train.csv')\n",
    "data_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_preprocessing(dataset):\n",
    "    # Delete Cabin and PassengerId features because they don't add nothing to our model\n",
    "    dataset = dataset.drop(['Cabin','PassengerId','Ticket'],axis=1)\n",
    "    \n",
    "    # Fill Age column with median\n",
    "    dataset['Age'].fillna(dataset['Age'].median(), inplace=True)\n",
    "    \n",
    "    # Fill Embarked with most occuring values\n",
    "    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace=True)\n",
    "    \n",
    "    # Fill Embarked with most occuring values\n",
    "    dataset['Fare'].fillna(dataset['Fare'].median(), inplace=True)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_feature_engineering(dataset):\n",
    "    # Extract title from Name column\n",
    "    dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\". \", expand=True)[0]\n",
    "    rare_titles = dataset['Title'].value_counts()[:4].index.tolist()\n",
    "    dataset.loc[~dataset['Title'].isin(rare_titles), 'Title'] = 'Rare'\n",
    "    \n",
    "#     # Fill Age column\n",
    "#     grouped_dataset = dataset.iloc[:891].groupby(['Sex', 'Pclass', 'Title'])\n",
    "#     grouped_median_dataset = grouped_dataset.median()\n",
    "#     grouped_median_dataset = grouped_median_dataset.reset_index()[['Sex', 'Pclass', 'Title', 'Age']]\n",
    "    \n",
    "#     def fill_age(row):\n",
    "#         condition = (\n",
    "#             (grouped_median_dataset['Sex'] == row['Sex']) &\n",
    "#             (grouped_median_dataset['Title'] == row['Title']) &\n",
    "#             (grouped_median_dataset['Pclass'] == row['Pclass'])\n",
    "#         )\n",
    "#         return grouped_median_dataset[condition]['Age'].values[0]\n",
    "\n",
    "#     def process_age(dataset):\n",
    "#         dataset['Age'] = dataset.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)\n",
    "#         return dataset\n",
    "\n",
    "#     dataset = process_age(dataset)\n",
    "    \n",
    "    # Bining\n",
    "    dataset['Fare_cut'] = pd.qcut(dataset['Fare'], q=10)\n",
    "    \n",
    "    # Create dummy variables\n",
    "    columns = ['Embarked', 'Title', 'Fare_cut']\n",
    "    dummy = pd.get_dummies(dataset[columns], dtype=np.int32)\n",
    "    dataset = pd.concat([dataset, dummy], axis=1)\n",
    "    dataset['Sex_dummy'] = dataset['Sex'].map({'male': 0, 'female': 1})\n",
    "    \n",
    "    # Size of the family\n",
    "    dataset['Family_size'] = dataset['SibSp'] + dataset['Parch']\n",
    "    \n",
    "    # Family size\n",
    "    dataset['Marriage'] = 0\n",
    "    dataset.loc[dataset['Family_size'] == 1, 'Marriage'] = 1\n",
    "    \n",
    "    dataset['S_family'] = 0\n",
    "    dataset.loc[(dataset['Family_size'] <= 4) & (dataset['Family_size'] >= 2), 'S_family'] = 1\n",
    "    \n",
    "    dataset['B_family'] = 0\n",
    "    dataset.loc[dataset['Family_size'] >= 5, 'B_family'] = 1\n",
    "    \n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['Family_size'] == 0, 'IsAlone'] = 1\n",
    "    \n",
    "    # Delete useless columns\n",
    "    dataset = dataset.drop(['Name', 'Sex', 'Embarked', 'Fare_cut', 'Title'], axis=1)\n",
    "    \n",
    "    return dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model):\n",
    "    # Train our model\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # F1-score\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print('F1-score: {}'.format(f1))\n",
    "    \n",
    "    \n",
    "    # Confusion matrix\n",
    "    print('Confusion Matrix: ')\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    group_names = ['True Negative','False Positive','False Negative','True Positive']\n",
    "    group_counts =['{0:0.0f}'.format(value) for value in matrix.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in matrix.flatten()/np.sum(matrix)]\n",
    "    \n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "\n",
    "    sns.heatmap(matrix, annot=labels, fmt='', cmap='rocket_r')\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_preparation(dataset):\n",
    "    dataset = titanic_preprocessing(dataset)\n",
    "    dataset = titanic_feature_engineering(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_prep = dataset_preparation(data_train)\n",
    "data_test_prep = dataset_preparation(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_train_prep.drop(['Survived'], axis=1)\n",
    "y = data_train_prep['Survived']\n",
    "\n",
    "# Scalling\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "data_test_scaled = scaler.fit_transform(data_test_prep)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-nearest neighbors \n",
    "KNN_model = KNeighborsClassifier()\n",
    "\n",
    "# SVC\n",
    "SVC_model = SVC()\n",
    "\n",
    "# Logistic regression\n",
    "LR_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Decision tree\n",
    "DT_model = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forest\n",
    "RF_model = RandomForestClassifier()\n",
    "\n",
    "# Stochastic gradient descent\n",
    "SGD_model = SGDClassifier()\n",
    "\n",
    "# XGBoost\n",
    "XGB_model = xgb.XGBClassifier(eta=0.01)\n",
    "\n",
    "# LightGBM\n",
    "LGBM_model = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_for_KNN = model_evaluation(KNN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_for_SVC = model_evaluation(SVC_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_for_LR = model_evaluation(LR_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_for_DT = model_evaluation(DT_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_for_RF = model_evaluation(RF_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_for_SGD = model_evaluation(SGD_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_for_XGB = model_evaluation(XGB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_for_LGBM = model_evaluation(LGBM_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "XGB_model = xgb.XGBClassifier(\n",
    "    reg_alpha = 0.1,\n",
    "    learning_rate =0.01,\n",
    "    n_estimators=1000,\n",
    "    # eta = 0.01,\n",
    "    gamma = 0,\n",
    "    reg_lambda = 0.5,\n",
    "    max_depth = 4,\n",
    "    main_child_weight = 0.5,\n",
    "    sampling_method = 'uniform',\n",
    "    subsample=1,\n",
    ")\n",
    "\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "model = XGB_model.fit(X_train, y_train, eval_metric=[\"error\", \"logloss\"], eval_set=eval_set, verbose=True, early_stopping_rounds=10)"
   ]
  },
  {
   "source": [
    "Best Score for XGB: 0.7853876288287601 \n",
    "With params: {'alpha': 0.5, 'eta': 0.05, 'gamma': 0, 'lambda': 0.5, 'max_depth': 4, 'min_child_weight': 0.5, 'sampling_method': 'uniform', 'subsample': 1}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "\n",
    "# search = GridSearchCV(XGB_model, parameters, verbose=3, scoring='f1')\n",
    "# search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Best Score for XGB: {} \\nWith params: {}'.format(search.best_score_, search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = XGB_model.evals_result()\n",
    "epochs = len(results['validation_0']['error'])\n",
    "x_axis = range(0, epochs)\n",
    "# plot log loss\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "ax.legend()\n",
    "plt.ylabel('Log Loss')\n",
    "plt.title('XGBoost Log Loss')\n",
    "plt.show()\n",
    "# plot classification error\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "ax.legend()\n",
    "plt.ylabel('Classification Error')\n",
    "plt.title('XGBoost Classification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = XGB_model.predict(X_test)\n",
    "f1_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = XGB_model.predict(data_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'PassengerId': data_test.PassengerId, 'Survived': y_pred})\n",
    "my_submission.to_csv('submission_v8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}