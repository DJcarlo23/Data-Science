{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello everyone! This is my solution for this month tabular playground. I learned a lot during my work on this dataset and from notebooks of other participants. Those two kernels were most helpfull and informative. Don't forget to check them too :D <br>\n",
    "[TPS-May Categorical EDA](https://www.kaggle.com/subinium/tps-may-categorical-eda) <br>\n",
    "[TPS May: RAPIDS](https://www.kaggle.com/ruchi798/tps-may-rapids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import umap.umap_ as umap\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# ML\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data/train.csv').drop('id', axis=1)\n",
    "data_test = pd.read_csv('data/test.csv').drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([data_train, data_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>EDA</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Missing values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there aren't any missing values in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Description</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.describe().T.style.bar(subset=['mean', 'std'], color='#d65f5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.describe().T.style.bar(subset=['mean', 'std'], color='#d65f5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Target Distribution</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "to_plot = data_train.value_counts('target')\n",
    "\n",
    "fig.add_trace(go.Pie(\n",
    "    labels = to_plot.index,\n",
    "    values = to_plot.values,\n",
    "    textinfo='label+percent'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',\n",
    "    title_text = 'Target Distribution'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately we have huge disbalance in our target variable. We will do something with this if it's gona be a problem later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Features Distribution</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=10,\n",
    "    cols=5,\n",
    "    subplot_titles=data_train.columns,\n",
    ")\n",
    "\n",
    "# Add traces\n",
    "columns = data_train.drop('target', axis=1).columns.tolist()\n",
    "\n",
    "for row in range(10):\n",
    "    for col in range(5):\n",
    "        column = columns.pop(0)\n",
    "        to_plot = data_train[column].value_counts()\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = to_plot.index,\n",
    "            y = to_plot.values,\n",
    "            name = column,\n",
    "            mode='lines'\n",
    "        ), col=col+1, row=row+1)\n",
    "\n",
    "        fig.update_yaxes(title='y', visible=False, showticklabels=False)\n",
    "\n",
    "        if(col+1 == 5):\n",
    "            break\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    width=700,\n",
    "    showlegend=False,\n",
    "    template='plotly_dark',\n",
    ")\n",
    "fig.update_annotations(font_size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of zero values in every feature. I'm curious how much of dataset is filled with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = data_train.drop('target', axis=1).isin([0]).sum(axis=0)\n",
    "percent = np.array(to_plot)/100000 * 100\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x = to_plot.values,\n",
    "    y = to_plot.index,\n",
    "    orientation='h',\n",
    "    text = np.round(percent, 2),\n",
    "    textposition='outside',\n",
    "    marker={\n",
    "        'color': to_plot.values,\n",
    "        'colorscale': 'Purples',\n",
    "\n",
    "    }\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    width=700,\n",
    "    template='plotly_dark',\n",
    "    title_text='Percent of zeros in every column'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Correlation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_target_num = data_train.replace({'target': {'Class_1': 1, 'Class_2': 2, 'Class_3': 3, 'Class_4': 4}})\n",
    "\n",
    "plt.figure(figsize=(8, 12))\n",
    "\n",
    "heatmap = sns.heatmap(data_train_target_num.corr()[['target']].sort_values(by='target', ascending=False),\n",
    "                     vmin=-1, vmax=1, annot=True, cmap='Purples')\n",
    "\n",
    "heatmap.set_title('Linear correlation of features with target variable', fontdict={'fontsize': 18}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some visualization and discussion couple of things come up to the light\n",
    "<ul>\n",
    "    <li>There aren't any missing values</li>\n",
    "    <li>Mean and standard deviation is fairly the same for train and test datasets</li>\n",
    "    <li>Target variable is unbalanced which can be a problem</li>\n",
    "    <li>Features are left skewed and nearly 60% of every feature is filled with zeros</li>\n",
    "    <li>Features show weak linear correlation with target variable</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dimensionality Reduction</h2>\n",
    "There is 50 features in our dataset. It's good opportunity to perform dimensionality reduction but first we gona check if it's necessary to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dimensionality reduction using PCA </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(data_train.drop('target', axis=1))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = list(range(50)),\n",
    "    y = np.cumsum(pca.explained_variance_ratio_)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    template = 'plotly_dark',\n",
    "    title_text = 'PCA Performence',\n",
    "    xaxis_title = 'Number of components',\n",
    "    yaxis_title = 'Cumulative explained variance'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from scatter plot above variance decreasing quite fast. By the time PCA reduce number of features to the 30 we had lost almost 10% of the variance. It's definitely not worth it to reduce dimensionality of this dataset in order to create prediction model but still we can use dimensionality reduction to visualize our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_vis = PCA(3)\n",
    "projected = pca_vis.fit_transform(data_train.drop('target', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vis = pd.DataFrame(projected, columns=['x', 'y', 'z'])\n",
    "df_vis['target'] = data_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df_vis, x='x', y='y', z='z', color='target')\n",
    "\n",
    "# tight layout\n",
    "fig.update_layout(\n",
    "    template='plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA doesn't work very well but it's doesn't mean that visualization is impossible we gonna use other method to do so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Dimensionality reduction using umap </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_train = data_train.sample(1000, random_state=42)\n",
    "scaled_sample_train = pd.DataFrame(StandardScaler().fit_transform(sample_data_train.drop('target', axis=1)))\n",
    "scaled_sample_target = sample_data_train.replace({'target': {'Class_1': 1, 'Class_2': 2, 'Class_3': 3, 'Class_4': 4}})['target'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer_2d = umap.UMAP(random_state=1)\n",
    "embedding_2d = reducer_2d.fit_transform(scaled_sample_train, scaled_sample_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_2d = pd.DataFrame(embedding_2d, columns=['x', 'y'])\n",
    "df_test_2d['target'] = scaled_sample_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = df_test_2d[df_test_2d['target'] == 1]['x'],\n",
    "    y = df_test_2d[df_test_2d['target'] == 1]['y'],\n",
    "    mode='markers',\n",
    "    name='Class_1'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = df_test_2d[df_test_2d['target'] == 2]['x'],\n",
    "    y = df_test_2d[df_test_2d['target'] == 2]['y'],\n",
    "    mode='markers',\n",
    "    name='Class_2'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = df_test_2d[df_test_2d['target'] == 3]['x'],\n",
    "    y = df_test_2d[df_test_2d['target'] == 3]['y'],\n",
    "    mode='markers',\n",
    "    name='Class_3'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = df_test_2d[df_test_2d['target'] == 4]['x'],\n",
    "    y = df_test_2d[df_test_2d['target'] == 4]['y'],\n",
    "    mode='markers',\n",
    "    name='Class_4'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = '2d dataset visualization using UMAP',\n",
    "    template = 'plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer_3d = umap.UMAP(random_state=42, n_components=3)\n",
    "embedding_3d = reducer_3d.fit_transform(scaled_sample_train, scaled_sample_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_3d = pd.DataFrame(embedding_3d, columns=['x', 'y', 'z'])\n",
    "df_test_3d['target'] = scaled_sample_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x = df_test_3d[df_test_3d['target'] == 1]['x'],\n",
    "    y = df_test_3d[df_test_3d['target'] == 1]['y'],\n",
    "    z = df_test_3d[df_test_3d['target'] == 1]['z'],\n",
    "    mode = 'markers',\n",
    "    name = 'Class_1',\n",
    "    marker = dict(\n",
    "        size=4\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x = df_test_3d[df_test_3d['target'] == 2]['x'],\n",
    "    y = df_test_3d[df_test_3d['target'] == 2]['y'],\n",
    "    z = df_test_3d[df_test_3d['target'] == 2]['z'],\n",
    "    mode = 'markers',\n",
    "    name = 'Class_2',\n",
    "    marker = dict(\n",
    "        size=4\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x = df_test_3d[df_test_3d['target'] == 3]['x'],\n",
    "    y = df_test_3d[df_test_3d['target'] == 3]['y'],\n",
    "    z = df_test_3d[df_test_3d['target'] == 3]['z'],\n",
    "    mode = 'markers',\n",
    "    name = 'Class_3',\n",
    "    marker = dict(\n",
    "        size=4\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x = df_test_3d[df_test_3d['target'] == 4]['x'],\n",
    "    y = df_test_3d[df_test_3d['target'] == 4]['y'],\n",
    "    z = df_test_3d[df_test_3d['target'] == 4]['z'],\n",
    "    mode = 'markers',\n",
    "    name = 'Class_4',\n",
    "    marker = dict(\n",
    "        size=4\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = '3d dataset visualization using UMAP',\n",
    "    template = 'plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our visualization looks much better we can clearly see clouds of different classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Prediction model creation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_num = data_train\n",
    "\n",
    "X = data_train_num.drop('target', axis=1)\n",
    "y = data_train_num['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Scalling </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> XGBoost </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pred = np.zeros((len(X), 4))\n",
    "test_pred = np.zeros((len(data_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold_, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "    print('Fold: ', fold_)\n",
    "    model = xgb_model.fit(\n",
    "        X.iloc[train_index],\n",
    "        y.iloc[train_index],\n",
    "        eval_set = [(X.iloc[train_index], y.iloc[train_index]), (X.iloc[val_index], y.iloc[val_index])],\n",
    "        eval_metric = 'mlogloss',\n",
    "        early_stopping_rounds = 50, \n",
    "        verbose = 0\n",
    "    )\n",
    "\n",
    "    temp_pred = model.predict_proba(X.iloc[val_index])\n",
    "    log_pred[val_index] = temp_pred\n",
    "\n",
    "    print(f'Log Loss: {log_loss(y.iloc[val_index], temp_pred)}')\n",
    "\n",
    "    temp_test = model.predict_proba(data_test)\n",
    "    test_pred += temp_test\n",
    "\n",
    "test_pred1 = test_pred/5\n",
    "\n",
    "print(f'Overall Log Loss: {log_loss(y, log_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Light Gradient Boost </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pred = np.zeros((len(X), 4))\n",
    "test_pred = np.zeros((len(data_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold_, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "    print('Fold: ', fold_)\n",
    "    model = lg_model.fit(\n",
    "        X.iloc[train_index],\n",
    "        y.iloc[train_index],\n",
    "        eval_set = [(X.iloc[train_index], y.iloc[train_index]), (X.iloc[val_index], y.iloc[val_index])],\n",
    "        eval_metric = 'multi_logloss',\n",
    "        early_stopping_rounds = 50,\n",
    "        verbose = 0\n",
    "    )\n",
    "\n",
    "    temp_pred = model.predict_proba(X.iloc[val_index])\n",
    "    log_pred[val_index] = temp_pred\n",
    "\n",
    "    print(f'Log Loss: {log_loss(y.iloc[val_index], temp_pred)}')\n",
    "\n",
    "    temp_test = model.predict_proba(data_test)\n",
    "    test_pred += temp_test\n",
    "\n",
    "test_pred2 = test_pred/5\n",
    "\n",
    "print(f'Overall Log Loss: {log_loss(y, log_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Catboost </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pred = np.zeros((len(X), 4))\n",
    "test_pred = np.zeros((len(data_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for fold_, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "    print('Fold: ', fold_)\n",
    "    model = cat_model.fit(\n",
    "        X.iloc[train_index],\n",
    "        y.iloc[train_index],\n",
    "        eval_set = [(X.iloc[train_index], y.iloc[train_index]), (X.iloc[val_index], y.iloc[val_index])],\n",
    "        early_stopping_rounds = 50,\n",
    "        verbose=0\n",
    "\n",
    "    )\n",
    "\n",
    "    temp_pred = model.predict_proba(X.iloc[val_index])\n",
    "    log_pred[val_index] = temp_pred\n",
    "\n",
    "    print(f'Log Loss: {log_loss(y.iloc[val_index], temp_pred)}')\n",
    "\n",
    "    temp_test = model.predict_proba(data_test)\n",
    "    test_pred += temp_test\n",
    "\n",
    "test_pred3 = test_pred/10\n",
    "\n",
    "print(f'Overall Log Loss: {log_loss(y, log_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred1 = pd.DataFrame(test_pred1)\n",
    "df_pred2 = pd.DataFrame(test_pred2)\n",
    "df_pred3 = pd.DataFrame(test_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test1 = pd.read_csv('data/sample_submission.csv').drop(['Class_1', 'Class_2', 'Class_3', 'Class_4'], axis=1)\n",
    "\n",
    "data_test1['Class_1'] = df_pred1[0]\n",
    "data_test1['Class_2'] = df_pred1[1]\n",
    "data_test1['Class_3'] = df_pred1[2]\n",
    "data_test1['Class_4'] = df_pred1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test2 = pd.read_csv('data/sample_submission.csv').drop(['Class_1', 'Class_2', 'Class_3', 'Class_4'], axis=1)\n",
    "\n",
    "data_test2['Class_1'] = df_pred2[0]\n",
    "data_test2['Class_2'] = df_pred2[1]\n",
    "data_test2['Class_3'] = df_pred2[2]\n",
    "data_test2['Class_4'] = df_pred2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test3 = pd.read_csv('data/sample_submission.csv').drop(['Class_1', 'Class_2', 'Class_3', 'Class_4'], axis=1)\n",
    "\n",
    "data_test3['Class_1'] = df_pred3[0]\n",
    "data_test3['Class_2'] = df_pred3[1]\n",
    "data_test3['Class_3'] = df_pred3[2]\n",
    "data_test3['Class_4'] = df_pred3[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test3.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
