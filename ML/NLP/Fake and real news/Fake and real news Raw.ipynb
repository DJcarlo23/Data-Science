{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, log_loss\n",
    "\n",
    "# ML\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true = pd.read_csv('D:/Data/Fake and real news/True.csv')\n",
    "data_fake = pd.read_csv('D:/Data/Fake and real news/Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels\n",
    "data_true['target'] = np.ones(data_true.shape[0])\n",
    "data_fake['target'] = np.zeros(data_fake.shape[0])\n",
    "\n",
    "# Create one big dataframe\n",
    "dataframes = [data_true, data_fake]\n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Shuffle new dataframe\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Pull out only text and target features\n",
    "data = data[['text', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Exploratory Data Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "to_plot = data.value_counts('target')\n",
    "\n",
    "fig.add_trace(go.Pie(\n",
    "    labels = to_plot.index.map({0: 'Fake', 1: 'True'}),\n",
    "    values = to_plot.values,\n",
    "    textinfo = 'label+percent'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    template = 'plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are lucky because our dataset is fairly balanced. With this information our work will be easier. No we will check couple of common attributes of text data like number of words or number of letters in news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1, subplot_titles=('True news', 'Fake news'))\n",
    "\n",
    "news_len_true = data[data['target']==1]['text'].str.len()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=news_len_true, name='True news', nbinsx=500),\n",
    "    row=1, \n",
    "    col=1\n",
    ")\n",
    "\n",
    "news_len_false = data[data['target']==0]['text'].str.len()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=news_len_false, name='Fake news', nbinsx=500),\n",
    "    row=2, \n",
    "    col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',\n",
    "    title_text='Number of characters in news'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1, subplot_titles=('True news', 'Fake news'))\n",
    "\n",
    "word_len_true = data[data['target']==1]['text'].str.split().map(lambda x: len(x))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=word_len_true, name='True news'),\n",
    "    row=1,\n",
    "    col=1\n",
    ")\n",
    "\n",
    "word_len_false = data[data['target']==0]['text'].str.split().map(lambda x: len(x))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=word_len_false, name='Fake news'),\n",
    "    row=2,\n",
    "    col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',\n",
    "    title_text='Number of words in words'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Common stopwords</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_list(target):\n",
    "    words=[]\n",
    "\n",
    "    for x in data[data['target']==target]['text'].str.split():\n",
    "        for i in x:\n",
    "            words.append(i)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list_true = words_list(1)\n",
    "stop = stopwords.words('english')\n",
    "dic = defaultdict(int)\n",
    "\n",
    "for word in words_list_true:\n",
    "    if word in stop:\n",
    "        dic[word] += 1\n",
    "\n",
    "top = sorted(dic.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "x, y = zip(*top)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=x,\n",
    "    y=y\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',\n",
    "    title_text='Common stopwords in true news'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list_true = words_list(0)\n",
    "stop = stopwords.words('english')\n",
    "dic = defaultdict(int)\n",
    "\n",
    "for word in words_list_true:\n",
    "    if word in stop:\n",
    "        dic[word] += 1\n",
    "\n",
    "top = sorted(dic.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "x, y = zip(*top)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=x,\n",
    "    y=y\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',\n",
    "    title_text='Common stopwords in fake news'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Punctuations</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = words_list(1)\n",
    "\n",
    "dic = defaultdict(int)\n",
    "special = string.punctuation\n",
    "for p in punctuations:\n",
    "    if p in special:\n",
    "        dic[p] += 1\n",
    "\n",
    "x, y = zip(*dic.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x = x,\n",
    "    y = y\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = 'Punctuations for true news',\n",
    "    template='plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = words_list(0)\n",
    "\n",
    "dic = defaultdict(int)\n",
    "special = string.punctuation\n",
    "for p in punctuations:\n",
    "    if p in special:\n",
    "        dic[p] += 1\n",
    "\n",
    "x, y = zip(*dic.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x = x,\n",
    "    y = y\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = 'Punctuations for fake news',\n",
    "    template='plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Common words</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(words_list(1))\n",
    "most_common = counter.most_common()\n",
    "\n",
    "x = list()\n",
    "y = list()\n",
    "\n",
    "for word, count in most_common[:50]:\n",
    "    if word not in stop:\n",
    "        x.append(word)\n",
    "        y.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x = x,\n",
    "    y = y\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = 'Common words true news',\n",
    "    template='plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(words_list(0))\n",
    "most_common = counter.most_common()\n",
    "x = list()\n",
    "y = list()\n",
    "\n",
    "for word, count in most_common[:70]:\n",
    "    if word not in stop:\n",
    "        x.append(word)\n",
    "        y.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x = x,\n",
    "    y = y\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = 'Common words for fake news',\n",
    "    template='plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Text Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Removing urls</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete url from all rows\n",
    "data['text'] = data['text'].apply(lambda x: remove_URL(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Removing Emojis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete emojis from all rows\n",
    "data['text'] = data['text'].apply(lambda x: remove_emoji(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Removing punctuacions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    \"\"\"This function creates a dictionary mapping of every character from string.punctuation to None\"\"\"\n",
    "    table = str.maketrans('','', string.punctuation)\n",
    "    return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete punctuations from all rows\n",
    "data['text'] = data['text'].apply(lambda x: remove_punctuations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Prediction Model Creation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[:40000]\n",
    "data_test = data[40000:41000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = data_train.sample(5000).reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "data_train_vector = pd.DataFrame(vectorizer.fit_transform(reduced_data['text']).toarray())\n",
    "data_test_vector = pd.DataFrame(vectorizer.transform(data_test['text']).toarray())\n",
    "data_train_vector['target'] = reduced_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_train_vector.drop(['target'], axis=1)\n",
    "y = data_train_vector['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = CatBoostClassifier()\n",
    "\n",
    "log_pred = np.zeros(len(X))\n",
    "test_pred = np.zeros(len(data_test_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold_, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "    print('Fold: ', fold_)\n",
    "    model = cat_model.fit(\n",
    "        X.iloc[train_index],\n",
    "        y.iloc[train_index],\n",
    "        eval_set = [(X.iloc[train_index], y.iloc[train_index]), (X.iloc[val_index], y.iloc[val_index])],\n",
    "        early_stopping_rounds = 10,\n",
    "        verbose = False,\n",
    "    )\n",
    "\n",
    "    temp_pred = model.predict(X.iloc[val_index])\n",
    "    log_pred[val_index] = temp_pred\n",
    "\n",
    "    print(f'F1-score: {f1_score(y.iloc[val_index], temp_pred)}')\n",
    "\n",
    "    temp_test = model.predict(data_test_vector)\n",
    "    test_pred += temp_test\n",
    "\n",
    "final_pred = np.zeros(len(test_pred))\n",
    "for index, pred in enumerate(test_pred):\n",
    "    if(pred >= 3):\n",
    "        final_pred[index] = 1\n",
    "\n",
    "print(f'Overall F1-score: {f1_score(y, log_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Performance on test data (F1-score): {}'.format(f1_score(data_test['target'], final_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
