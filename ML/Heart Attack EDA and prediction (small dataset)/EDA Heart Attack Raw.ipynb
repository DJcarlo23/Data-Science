{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Hello everyone!</h1></center>\n",
    "I created a notebook where I made a little of analysis and prediction. I hope you will like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import seaborn as sns\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Machine learning models\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data\\heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Preparation</h1>\n",
    "First we need to check if there is any missing values or outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's looks like our data is fully filled with values. We don't need to worry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot(column, plot_name):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Box(\n",
    "        y = column,\n",
    "        name = ''\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        template = 'plotly_dark',\n",
    "        title_text = plot_name\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(data['age'], 'Age box plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(data['trtbps'], 'Resting blood pressure box plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see couple of outliers but they are not that significante and probably they are not outliers at all. Someone probably had sucha a high score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(data['chol'], 'Cholesterol box plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['chol'] > 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this situation we should think about this high cholesterol measurement. After a couple of minutes of research I can tell that measurement of over 500 is possible if we measure triglycerides but still, it would be a problem for our prediction in the future. We will delete this row from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_del = data[data['chol'] < 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(data_del['chol'], 'Cholesterol box plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(data_del['thalachh'], 'Maximum heart rate achieved box plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(data_del['oldpeak'], 'Previous peak box plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Exploratory data analysis</h1>\n",
    "First we have to answer a very important question. How does each feature affect our goal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "to_plot = data_del['output'].replace({0: 'Less chance of heart attack', 1: 'More chance of heart attack'}).value_counts()\n",
    "labels = to_plot.index\n",
    "values = to_plot.values\n",
    "\n",
    "fig.add_trace(go.Pie(\n",
    "    labels = labels,\n",
    "    values = values,\n",
    "    textinfo='percent'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Survival',\n",
    "    template='plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can be happy that our dataset is balanced. It will be easier to perform prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Histogram(\n",
    "    x = data_del[data_del['output'] == 0]['age'],\n",
    "    name = 'Less chance of heart attack'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Histogram(\n",
    "    x = data_del[data_del['output'] == 1]['age'],\n",
    "    name = 'More chance of heart attack'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    width = 1000,\n",
    "    template = 'plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: People between 40 and 55 years of age have more chance to have a stroke. Which is a little weird in my opinion. I always thought that stroke chance increase with age. Unfortunately with this dataset we don't have enough data to verify it. Therefore, this thought will remain only a guess.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male vs female chance of stroke\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}]], subplot_titles=['Female', 'Male'])\n",
    "\n",
    "to_plot_female = data_del[data_del['sex'] == 0]['output'].replace({0: 'Less chance of heart attack', 1: 'More chance of heart attack'}).value_counts()\n",
    "labels_female = to_plot_female.index\n",
    "values_female = to_plot_female.values\n",
    "\n",
    "to_plot_male = data_del[data_del['sex'] == 1]['output'].replace({0: 'Less chance of heart attack', 1: 'More chance of heart attack'}).value_counts()\n",
    "labels_male = to_plot_male.index\n",
    "values_male = to_plot_male.values\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "    labels = labels_female,\n",
    "    values = values_female,\n",
    "    textinfo='percent',\n",
    "    name='Female'),\n",
    "    row=1,\n",
    "    col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "    labels = labels_male,\n",
    "    values = values_male,\n",
    "    textinfo='percent',\n",
    "    name='Man'),\n",
    "    row=1,\n",
    "    col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Male vs Female chance of stroke',\n",
    "    template='plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance of sex feature\n",
    "to_plot_balance = data_del['sex'].replace({0: 'Female', 1: 'Male'}).value_counts()\n",
    "labels_balance = to_plot_balance.index\n",
    "values_balance = to_plot_balance.values\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Pie(\n",
    "    labels = labels_balance,\n",
    "    values = values_balance\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Population by gender',\n",
    "    template='plotly_dark'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Women are more prone to heart attacks <br>\n",
    "From plots above we can tell that females have more chance of stroke but at the same time data are fairly unbalanced. This makes this conclusion irrelevant in my opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trtbps_1 = data_del[data_del['output'] == 1]['trtbps']\n",
    "trtbps_0 = data_del[data_del['output'] == 0]['trtbps']\n",
    "\n",
    "# Group data together\n",
    "hist_data = [trtbps_1, trtbps_0]\n",
    "group_labels = ['More chance of heart attack', 'Less chance of heart attack']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = 'Resting blood pressure by stroke chance'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Resting blood pressure isn't correlated with chance of heart stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chol_1 = data_del[data_del['output'] == 1]['chol']\n",
    "chol_0 = data_del[data_del['output'] == 0]['chol']\n",
    "\n",
    "# Group data together\n",
    "hist_data = [chol_1, chol_0]\n",
    "group_labels = ['More chance of heart attack', 'Less chance of heart attack']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = 'Cholesterol by stroke chance'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: People with cholesterol level (mg/dl) between 170 and 250 have more chance of stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thalachh_1 = data_del[data_del['output'] == 1]['thalachh']\n",
    "thalachh_0 = data_del[data_del['output'] == 0]['thalachh']\n",
    "\n",
    "# Group data together\n",
    "hist_data = [thalachh_1, thalachh_0]\n",
    "group_labels = ['More chance of heart attack', 'Less chance of heart attack']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = 'Maximum heart rate achieved by stroke chance'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: People who achieved maximum heart rate larger than 150 have very big chance to experience a heart attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check correlation of other features with heart stroke chance we'll go the easy way and simply display pearson correlation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "\n",
    "heatmap = sns.heatmap(data.corr()[['output']].sort_values(by='output', ascending=False),\n",
    "                     vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "\n",
    "heatmap.set_title('Features correlated with chance of stroke', fontdict={'fontsize': 18}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: This chart shows that only two features (fbs and cho) aren't correlated with stroke chance at all. Rest of them are fairly correlated which can be helpful in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Prediction</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = data_del.drop(['output'], axis=1)\n",
    "y = data_del['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale values\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model):\n",
    "    # Train our model and predict\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Cross validation\n",
    "    scores = cross_val_score(model, X, y, cv=3, scoring='f1')\n",
    "    f1_scores_mean = scores.mean()\n",
    "    print('F1 scores: {}'.format(scores))\n",
    "    print('F1 mean score: {}'.format(f1_scores_mean))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print('Confusion Matrix: ')\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    group_names = ['True Negative','False Positive','False Negative','True Positive']\n",
    "    group_counts =['{0:0.0f}'.format(value) for value in matrix.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in matrix.flatten()/np.sum(matrix)]\n",
    "    \n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "\n",
    "    sns.heatmap(matrix, annot=labels, fmt='', cmap='rocket_r')\n",
    "    \n",
    "    return f1_scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-nearest neighbors \n",
    "KNN_model = KNeighborsClassifier()\n",
    "\n",
    "# SVC\n",
    "SVC_model = SVC()\n",
    "\n",
    "# Logistic regression\n",
    "LR_model = LogisticRegression()\n",
    "\n",
    "# Decision tree\n",
    "DT_model = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forest\n",
    "RF_model = RandomForestClassifier()\n",
    "\n",
    "# XGBoost\n",
    "XGB_model = xgb.XGBClassifier()\n",
    "\n",
    "# LightGBM\n",
    "LGBM_model = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_KNN = model_evaluation(KNN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_SVC = model_evaluation(SVC_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_LR = model_evaluation(LR_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_DT = model_evaluation(DT_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_RF = model_evaluation(RF_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_XGB = model_evaluation(XGB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_LGBM = model_evaluation(LGBM_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results we see that models are unstable and accuracy jumps uncontrollably. I'm pretty sure that is a result of the small size of the dataset. We will try to tune the logistic regression model to make him more stable. I choose this algorithm because he is simple and that kind of models works best for small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_new = LogisticRegression(\n",
    "    penalty = 'l2',\n",
    "    C = 0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(LR_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! After we added a regularization parameter our model become more stable. We achieved our goal, the model doesn't look overfitted and accuracy is fair enough for such small dataset. I think we can leave it like this. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
